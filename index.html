<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Open Catalyst Project</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/mint.css">
	<link rel="stylesheet" href="dist/theme/skelet.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section>
				<article>
					<x-grid columns=4 ai="end">
						<x-col>
							<h2 class="r-fit-text">Open Catalyst Project</h2>
							<h2 class="r-fit-text">Project Sync</h2>
						</x-col>
						<x-col span="2+3">
							<figure><img src="assets/intel-logo.svg" alt=""></figure>
						</x-col>
					</x-grid>
					<footer style="padding-top: 2vw;">
						<x-grid columns=3 ai="center">
							<x-col>
								<p>Kelvin Lee</p>
								<em>HPC AI for Science Working Group</em>
							</x-col>
						</x-grid>
					</footer>
				</article>
			</section>
			<section>
				<x-grid columns="3" ai="center">
					<x-col>
						<h1>TOC</h1>
					</x-col>
					<x-col span="2+2">
						<ol>
							<li>Last time on OCP</li>
							<li>DimeNet++ architecture</li>
							<li>Single node profiling</li>
						</ol>
					</x-col>
				</x-grid>
			</section>
			<section>
				<section>
					<h2>Last time on OCP</h2>
					<x-grid columns="3" ai="center">
						<x-col>
							<p>PyTorch Lightning refactor</p>
							<em>Data, model, distributed abstraction</em>
						</x-col>
						<x-col>
							<p>Working training pipeline with DGL</p>
						</x-col>
						<x-col>
							<p>Qualitative throughput improvement with <span class="monospace">GCNConv</span></p>
						</x-col>
					</x-grid>
				</section>
				<section>
					<x-grid columns="2" ai="top">
						<x-col>
							<p>YAML pipeline configuration</p>
							<pre><code>model:
		gnn: 
		class_path: ocpmodels.models.dimenetpp_dgl.DimeNetPP
		init_args:
			emb_size: 128
			out_emb_size: 256
			int_emb_size: 64
			basis_emb_size: 8
			num_blocks: 3
			num_spherical: 7
			num_radial: 6
			cutoff: 10.
			envelope_exponent: 5.0
			activation: torch.nn.SiLU
		regress_forces: False
		normalize_kwargs:
		target_mean: -0.7554450631141663
		target_std: 2.887317180633545
		grad_target_mean: 0.0
		grad_target_std: 2.887317180633545
	data:
		class_path: ocpmodels.lightning.data.DGLDataModule
		init_args:
		train_path: "../data/s2ef/200k/train"
		batch_size: 32
		num_workers: 8
	optimizer:
		class_path: torch.optim.Adam
		init_args:
		lr: 0.0005
	lr_scheduler:
		class_path: torch.optim.lr_scheduler.ExponentialLR
		init_args:
		gamma: 0.1
	trainer:
		max_steps: 100
		limit_val_batches: 0
		limit_test_batches: 0
		limit_predict_batches: 0
		accelerator: "cpu"
		num_nodes: 1
		num_processes: 1
		strategy: null
		profiler: "pytorch"
	seed_everything: 42</code></pre>
						</x-col>
						<x-col>
							<p>Lightning CLI</p>
							<pre><code>python -m ocpmodels.lightning.s2ef fit --config dimenetpp.yml</code></pre>
						</x-col>
					</x-grid>
				</section>
			</section>
			<section>
				<section>
					<h2>DimeNet++ architecture</h2>
				</section>
				<section>
					<h2>What is DimeNet?</h2>
					<x-grid columns="3" ai="center">
						<x-col>
							<ul>
								<li>Directional message passing model</li>
								<li>Uses Gaussian and Bessel basis functions for invariance</li>
								<li>All of the complexity for incremental predictive performance</li>
							</ul>
						</x-col>
						<x-col span="2+2">
							<figure>
								<img src="assets/dimenetpp.png" alt="">
								<caption>
									<p>Block diagrams for DimeNet++</p>
								</caption>
							</figure>
						</x-col>
					</x-grid>
				</section>
				<section>
					<p>Implementation from <a href="https://github.com/xnuohz/DimeNet-dgl">xnuohz/DimeNet-dgl</a></p>
					<p>Refactors by me to support OCP</p>
				</section>
				<section>
					<x-grid columns="3" ai="center">
						<x-col span="1+2">
							<pre><code>def forward(self, g: dgl.DGLGraph) -> torch.Tensor:
	g = self.edge_distance(g)
	l_g = self._create_line_graph(g)
	# add rbf features for each edge in one batch graph, [num_radial,]
	g = self.rbf_layer(g)
	# Embedding block
	g = self.emb_block(g)
	# Output block
	P = self.output_blocks[0](g)  # [batch_size, num_targets]
	# Prepare sbf feature before the following blocks
	for k, v in g.edata.items():
		l_g.ndata[k] = v

	l_g.apply_edges(self.edge_init)
	# Interaction blocks
	for i in range(self.num_blocks):
		g = self.interaction_blocks[i](g, l_g)
		P += self.output_blocks[i + 1](g)
	return P</code></pre>
						</x-col>
						<x-col>
							<ol>
								<li>Compute interatomic distances from Cartesians</li>
								<li>Expand Gaussian/Bessel basis</li>
								<li>Compute message passing and MLP blocks</li>
								<li>Output energy</li>
							</ol>
						</x-col>
					</x-grid>
				</section>
				<section>
					<h2>Basis functions</h2>
					<x-grid columns="3">
						<x-col>
							<p>
								Initialize edge distance properties from atom positions
							</p>
						</x-col>
						<x-col span="2+2">
							<pre><code>graph.apply_edges(
	lambda edge: {'r': (edge.src['pos'] - edge.dst['pos']).pow(2.).sum(dim=1)}
)</code></pre>
						</x-col>
					</x-grid>
				</section>
				<section>
					<h2>Radial basis functions</h2>
					<x-grid columns="3" ai="center">
						<x-col>
							<p>Expand in enveloped Gaussian basis</p>
						</x-col>
						<x-col span="2+2">
							<pre><code>def forward(self, g: dgl.DGLGraph) -> dgl.DGLGraph:
	d_scaled = (g.edata['r'] / self.cutoff).unsqueeze(-1)
	d_cutoff = self.envelope(d_scaled)
	g.edata['rbf'] = d_cutoff * torch.sin(self.frequencies * d_scaled)
	return g</code></pre>
							<pre><code>def forward(self, x: torch.Tensor) -> torch.Tensor:
	# Envelope function divided by r
	x_p_0 = x.pow(self.p - 1)
	x_p_1 = x_p_0 * x
	x_p_2 = x_p_1 * x
	env_val = 1 / x + self.a * x_p_0 + self.b * x_p_1 + self.c * x_p_2
	return env_val</code></pre>
						</x-col>
					</x-grid>
				</section>
				<section>
					<h2>Angular Bessel basis</h2>
					<x-grid columns="3" ai="center">
						<x-col>
							<p>Lambdify analytic expressions for radial and angular basis</p>
						</x-col>
						<x-col span="2+2">
							<pre><code># convert to torch functions
x = sym.symbols("x")
theta = sym.symbols("theta")
modules = {"sin": torch.sin, "cos": torch.cos}
for i in range(num_spherical):
	if i == 0:
		first_sph = sym.lambdify(
			[theta], self.sph_harm_formulas[i][0], modules
		)(0)
		self.sph_funcs.append(
			lambda tensor: torch.zeros_like(tensor) + first_sph
		)
	else:
		self.sph_funcs.append(
			sym.lambdify([theta], self.sph_harm_formulas[i][0], modules)
		)
	for j in range(num_radial):
		self.bessel_funcs.append(
			sym.lambdify([x], self.bessel_formulas[i][j], modules)
		)</code></pre>
						</x-col>
					</x-grid>
				</section>
				<section>
					<x-grid columns="4" ai="center">
						<x-col span="1+2">
							<pre><code>def spherical_bessel_formulas(n):
	"""
	n: int
	res: array of shape [n,]
	n sympy functions
	Computes the sympy formulas for the spherical bessel functions up to order n (excluded)
	"""
	x = sym.symbols("x")

	f = [sym.sin(x) / x]
	a = sym.sin(x) / x
	for i in range(1, n):
		b = sym.diff(a, x) / x
		f += [sym.simplify(b * (-x) ** i)]
		a = sym.simplify(b)
	return f</code></pre>
						</x-col>
						<x-col span="3+2">
							<pre><code>def bessel_basis(n, k):
	"""
	n: int
	k: int
	res: [n, k]
	n * k sympy functions
	Computes the sympy formulas for the normalized and rescaled spherical bessel functions up to
	order n (excluded) and maximum frequency k (excluded).
	"""

	zeros = Jn_zeros(n, k)
	normalizer = []
	for order in range(n):
		normalizer_tmp = []
		for i in range(k):
			normalizer_tmp += [0.5 * Jn(zeros[order, i], order + 1) ** 2]
		normalizer_tmp = 1 / np.array(normalizer_tmp) ** 0.5
		normalizer += [normalizer_tmp]

	f = spherical_bessel_formulas(n)
	x = sym.symbols("x")
	bess_basis = []
	for order in range(n):
		bess_basis_tmp = []
		for i in range(k):
			bess_basis_tmp += [
				sym.simplify(
					normalizer[order][i]
					* f[order].subs(x, zeros[order, i] * x)
				)
			]
		bess_basis += [bess_basis_tmp]
	return bess_basis</code></pre>
						</x-col>
					</x-grid>
				</section>
				<section>
					<x-grid columns="2" ai="center">
						<x-col>
							<figure>
								<img src="assets/radial-bessel.png" alt="">
								<caption>
									<p>Radial Bessel basis</p>
								</caption>
							</figure>
						</x-col>
						<x-col>
							<figure>
								<img src="assets/angular-bessel.png" alt="">
								<caption>
									<p>Angular Bessel basis</p>
								</caption>
							</figure>
						</x-col>
					</x-grid>
				</section>
				<section>
					<h2>Atomic and basis embedding</h2>
					<x-grid columns="3" ai="center">
						<x-col>
							<p>Embed atom and distance information along edges</p>
						</x-col>
						<x-col span="2+2">
							<pre><code>g.ndata["h"] = self.embedding(g.ndata["atomic_numbers"].long())</code></pre>
							<pre><code># transform RBF
rbf = self.dense_rbf(edges.data["rbf"])
# concatenate node and rbf embeddings and transform
m = torch.cat([edges.src["h"], edges.dst["h"], rbf], dim=-1)
m = self.dense(m)</code></pre>
						</x-col>
					</x-grid>
				</section>
				<section>
					<h2>Angular basis embedding</h2>
					<x-grid columns="3" ai="center">
						<x-col>
							<ol>
								<li>Create line graph representation of molecule</li>
								<li>Compute angles between each line graph node (i.e. edges)</li>
								<li>Expand in spherical Bessel basis</li>
							</ol>
						</x-col>
						<x-col span="2+2">
							<pre><code>def edge_init(self, edges):
	# Calculate angles k -> j -> i
	R1, R2 = edges.src["o"], edges.dst["o"]
	x = torch.sum(R1 * R2, dim=-1)
	y = torch.cross(R1, R2)
	y = torch.norm(y, dim=-1)
	angle = torch.atan2(y, x)
	# Transform via angles
	cbf = [f(angle) for f in self.sbf_layer.get_sph_funcs()]
	cbf = torch.stack(cbf, dim=1)  # [None, 7]
	cbf = cbf.repeat_interleave(self.num_radial, dim=1)  # [None, 42]
	# Notice: it's dst, not src
	sbf = edges.dst["rbf_env"] * cbf  # [None, 42]
	return {"sbf": sbf}</code></pre>
						</x-col>
					</x-grid>
				</section>
				<section>
					<h2>Message passing</h2>
					<x-grid columns="3" ai="center">
						<x-col>
							<ol>
								<li>Copy edge data to line graph node data</li>
								<li>Transform bases and combine as message function</li>
								<li>Propagate messages, sum reduce</li>
								<li>Update messages, apply skip connections</li>
							</ol>
						</x-col>
						<x-col span="2+2">
							<pre><code>rbf = self.dense_rbf1(edges.data["rbf"])</code></pre>
							<pre><code>def msg_func(self, edges):
	sbf = self.dense_sbf1(edges.data["sbf"])
	sbf = self.dense_sbf2(sbf)
	x_kj = edges.src["x_kj"] * sbf
	return {"x_kj": x_kj}</code></pre>
							<pre><code>l_g_reverse.update_all(self.msg_func, fn.sum("x_kj", "m_update"))</code></pre>
							<pre><code>g.edata["m"] = g.edata["m"] + g.edata["m_update"]</code></pre>
						</x-col>
					</x-grid>
				</section>
				<section>
					<h2>Output blocks</h2>
					<x-grid columns="3" ai="center">
						<x-col>
							<p>Output blocks map edge basis back to nodes and perform readout</p>
						</x-col>
						<x-col span="2+2">
							<pre><code>def forward(self, g):
	with g.local_scope():
		g.edata["tmp"] = g.edata["m"] * self.dense_rbf(g.edata["rbf"])
		g_reverse = dgl.reverse(g, copy_edata=True)
		g_reverse.update_all(fn.copy_e("tmp", "x"), fn.sum("x", "t"))
		g.ndata["t"] = self.up_projection(g_reverse.ndata["t"])

		for layer in self.dense_layers:
			g.ndata["t"] = layer(g.ndata["t"])
			if self.activation is not None:
				g.ndata["t"] = self.activation(g.ndata["t"])
		g.ndata["t"] = self.dense_final(g.ndata["t"])
		return dgl.readout_nodes(g, "t", op="sum" if self.extensive else "mean")</code></pre>
						</x-col>
					</x-grid>
				</section>
				<section>
					<x-grid columns="3" ai="center">
						<x-col span="1+2">
							<pre><code>def forward(self, g: dgl.DGLGraph) -> torch.Tensor:
	g = self.edge_distance(g)
	l_g = self._create_line_graph(g)
	# add rbf features for each edge in one batch graph, [num_radial,]
	g = self.rbf_layer(g)
	# Embedding block
	g = self.emb_block(g)
	# Output block
	P = self.output_blocks[0](g)  # [batch_size, num_targets]
	# Prepare sbf feature before the following blocks
	for k, v in g.edata.items():
		l_g.ndata[k] = v

	l_g.apply_edges(self.edge_init)
	# Interaction blocks
	for i in range(self.num_blocks):
		g = self.interaction_blocks[i](g, l_g)
		P += self.output_blocks[i + 1](g)
	return P</code></pre>
						</x-col>
						<x-col>
							<ol>
								<li>Compute interatomic distances from Cartesians</li>
								<li>Expand Gaussian/Bessel basis</li>
								<li>Compute message passing and MLP blocks</li>
								<li>Output energy</li>
							</ol>
						</x-col>
					</x-grid>
				</section>
			</section>
			<section>
				<section>
					<figure><img src="assets/dimenet_block.svg" alt="" style="height: auto; max-width: 30%;">
					</figure>
				</section>
				<section>
					<h2>PyTorch profiling</h2>
					<x-grid columns="3" ai="center">
						<x-col>
							<p>PyTorch 1.11.0+MKL+OMP</p>
						</x-col>
						<x-col>
							<p>DGL <span class="monospace">0.8.0post2</span></p>
						</x-col>
						<x-col>
							<p>OCP <span class="monospace">37d6f7f</span></p>
						</x-col>
						<x-col>
							<p>Batch size 16</p>
						</x-col>
						<x-col>
							<p>Single process, NUMA aware</p>
						</x-col>
						<x-col>
							<p>4 data loaders</p>
						</x-col>
					</x-grid>
					<em>No PyG baseline for CPU; memory allocation issues for DimeNet++</em>
				</section>
			</section>
			<section>
				<h2>Laundry list</h2>
				<hr>
				<x-grid columns="2" ai="top">
					<x-col>
						<h3>Performance</h3>
						<ul>
							<li>Theoretical FLOPS model for DimeNet++</li>
							<li>Compare with <span class="monospace">DeepSpeed</span> FLOPS profile</li>
							<li>Roofline analysis</li>
							<li>CUDA PyG and DGL baseline</li>
						</ul>
					</x-col>
					<x-col>
						<h3>Science</h3>
						<ul>
							<li>Fix numerical overflow in radial basis</li>
							<li>Raise DGL double backprop issue</li>
							<li>Multinode training</li>
						</ul>
					</x-col>
				</x-grid>
			</section>
		</div>
	</div>
	<div id="slide-footer" class="footer">
		<x-grid columns="3" ai="center">
			<x-col>
				<small>Intel Confidential</small>
			</x-col>
			<x-col>
				<small>Intel AXG&middot;HPC EUE</small>
			</x-col>
			<x-col>
				<small>Kelvin Lee</small>
			</x-col>
		</x-grid>
	</div>

	<script src="plugin/skelet/app.js"></script>
	<script src="plugin/skelet/modules.js"></script>
	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/math/math.js"></script>
	<script src="plugin/zoom/zoom.js"></script>
	<script type="text/javascript">
		window.addEventListener("load", function () {

			revealDiv = document.querySelector("body div.reveal")
			footer = document.getElementById("slide-footer");
			revealDiv.appendChild(footer);

		});
	</script>
	<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
	<script>
		mermaid.initialize({
			startOnLoad: true,
		});
	</script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			slideNumber: true,
			transition: 'fade',
			transitionSpeed: 'slow',
			controlsLayout: 'edges',
			viewDistance: 50,
			preloadIframes: true,
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath, RevealZoom],
			dependencies: [{ src: 'plugin/mermaid/mermaid.js' }]
		});
	</script>
</body>

</html>